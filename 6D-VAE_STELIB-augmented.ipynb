{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Dimensional Variational Autoencoder trained with STELIB library (SVO)\n",
    "Based on data from the STELIB service developed by the Spanish Virtual Observatory in the framework of the IAU Comission G5 Working Group : Spectral Stellar Libraries\n",
    "http://svocats.cab.inta-csic.es/stelib/index.php\n",
    "Data set: http://svocats.cab.inta-csic.es/stelib/index.php?action=search\n",
    "\n",
    "Adrián García Riber and Francsico Serradilla.\n",
    "Polytechnic University of Madrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/adrian/Documents/FITS_Library/stelib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and name of one file to check the library\n",
    "file = root+\"/stelib_spec_fits_HD268623_moy.fits\"\n",
    "\n",
    "# Print the header\n",
    "sp = fits.open(file)\n",
    "print('\\n\\nHeader of the spectrum :\\n\\n', sp[0].header, '\\n\\n')\n",
    "\n",
    "# Extracting and normalizing the fluxes\n",
    "flux2 = np.array(sp[0].data)\n",
    "flux_norm = np.reshape(flux2/(np.nanmax(flux2)), (sp[0].header['NAXIS1']))\n",
    "\n",
    "# Extracting the wavelengths\n",
    "wave2 = np.ones(sp[0].header['NAXIS1'], dtype=float)\n",
    "for i in range(sp[0].header['NAXIS1']):\n",
    "    wave2[i] = sp[0].header['CRVAL1'] + i*sp[0].header['CDELT1']\n",
    "\n",
    "# Closing the fits-file\n",
    "sp.close()\n",
    "# Plot the spectrum\n",
    "fig = plt.figure(1, figsize=(12, 8))\n",
    "plt.plot(wave2, flux_norm)\n",
    "plt.xlabel('Wavelength [Å]')\n",
    "plt.ylabel('ADU')\n",
    "plt.title(file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the spectra and printing the spectrum dimension\n",
    "num = 1\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for nanme in files:\n",
    "        num += 1\n",
    "dim1 = sp[0].header['NAXIS1']\n",
    "print(num)\n",
    "print(dim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the custom_set with all the spectra and generating labels to enable recovering header information\n",
    "curves = 0\n",
    "custom_set = np.zeros((num, dim1))\n",
    "label_set = np.zeros((num, ), dtype=int)\n",
    "spectra_set = [''] * num \n",
    "\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        file = [os.path.join(path, name)]\n",
    "        str = \" \" \n",
    "        Ffile = (str.join(file))\n",
    "        route = Path(name)\n",
    "        Fname = route.with_suffix('')\n",
    "        Fpng = route.with_suffix('.png')\n",
    "\n",
    "        data, header = fits.getdata(Ffile, header=True)\n",
    "        hdu_number = 0\n",
    "        fits.getheader(Ffile, hdu_number)\n",
    "        fits_file = Ffile\n",
    "        \n",
    "        with fits.open(fits_file, mode='readonly') as hdulist:\n",
    "            hdulist.info()\n",
    "            data = np.array(hdulist[0].data)\n",
    "             \n",
    "            data_norm = np.reshape(data/(np.nanmax(data)), (sp[0].header['NAXIS1']))\n",
    "\n",
    "            \n",
    "            label_set[curves] = curves \n",
    "            spectra_set[curves] = name\n",
    "            for i in range (dim1):\n",
    "                custom_set[curves,i] = (data_norm[i])\n",
    "        hdulist.close   \n",
    "        curves += 1\n",
    "               \n",
    "        print (\"Spectra loaded:\",curves+1, \"spectra\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = np.asarray(label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmenting the dataset through the repetition of the spectra\n",
    "augmentation = 15\n",
    "custom_set = np.repeat(custom_set, augmentation, axis=0)\n",
    "label_set = np.repeat(label_set, augmentation, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the data set\n",
    "dataset = tf.data.Dataset.from_tensor_slices((custom_set, label_set))\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data set\n",
    "x_train,x_test,y_train,y_test=train_test_split(custom_set,label_set,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the VAE sampling function\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim), mean=0., stddev=0.00000001)#0.001_e-3\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the layers' dimensions\n",
    "original_dim = dim1\n",
    "latent_dim = 6\n",
    "intermediate_dim = dim1/3\n",
    "intermediate_dim2 = intermediate_dim/2\n",
    "intermediate_dim3 = intermediate_dim2/2\n",
    "intermediate_dim4 = intermediate_dim3/latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Encoder\n",
    "original_inputs = tf.keras.Input(shape=(original_dim,), name=\"encoder_input\")\n",
    "x1 = layers.Dense(intermediate_dim, activation=\"relu\")(original_inputs)\n",
    "x2 = layers.Dense(intermediate_dim2, activation=\"relu\")(x1)\n",
    "x3 = layers.Dense(intermediate_dim3, activation=\"relu\")(x2)\n",
    "x4 = layers.Dense(intermediate_dim4, activation=\"relu\")(x3)\n",
    "\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x4)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x4)\n",
    "z = Sampling()((z_mean, z_log_var))\n",
    "encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name=\"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Decoder\n",
    "latent_inputs = tf.keras.Input(shape=(latent_dim,), name=\"z_sampling\")\n",
    "x5 = layers.Dense(intermediate_dim4, activation=\"relu\")(latent_inputs)\n",
    "x6 = layers.Dense(intermediate_dim3, activation=\"relu\")(x5)\n",
    "x7 = layers.Dense(intermediate_dim2, activation=\"relu\")(x6)\n",
    "x8 = layers.Dense(intermediate_dim, activation=\"relu\")(x7)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(original_dim, activation=\"sigmoid\")(x8)\n",
    "decoder = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "outputs = decoder(z)\n",
    "vae6D = tf.keras.Model(inputs=original_inputs, outputs=outputs, name=\"VAE6D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae6D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding KL divergence regularization loss.\n",
    "kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "vae6D.add_loss(kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae6D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "vae6D.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
    "vae6D.fit(x_train, x_train, epochs=100, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "encoded_test = encoder(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_test = vae6D(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs_test=decoded_test.numpy()\n",
    "decoded_imgs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = 0\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "ax[0].plot(wave2, x_test[figure])\n",
    "ax[0].set_xlabel('Original Spectra')   \n",
    "ax[1].plot(wave2, decoded_imgs_test[figure])\n",
    "ax[1].set_xlabel('Decoded Spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(20):\n",
    "    figure = m\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    ax[0].plot(wave2, x_test[figure])\n",
    "    ax[0].set_xlabel('Original Spectra')   \n",
    "    ax[1].plot(wave2, decoded_imgs_test[figure])\n",
    "    ax[1].set_xlabel('Decoded Spectra')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the relation between original spectrum and decoded output\n",
    "for sample in range(20):\n",
    "    _ = plt.plot(x_test[sample], decoded_imgs_test[sample], 'o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating R_square for the test set\n",
    "r2_score(x_test, decoded_imgs_test, multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating R_square for each spectrum\n",
    "r2_score(x_test[0], decoded_imgs_test[0], multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = vae6D.get_weights()\n",
    "vae6D.save_weights('STELIB_6DVAE-augmented_Weights_OK', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae6D.save('STELIB_6DVAE-augmented_OK.tf', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save('STELIB_6D_Encoder-augmented_OK.tf', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.save('STELIB_6D_Decoder-augmented_OK.tf', save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
